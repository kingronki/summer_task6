{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition â€“ Unlock Your Computer With Your Face!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1 - Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-1-e8da5befbda5>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = 'E:/cnn/ronak' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 200: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "    if count == 100:\n",
    "        time.sleep(5)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = 'E:/cnn/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "ronak_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "ronak_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-6-fac1359ea61d>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the image id: \n",
      "Enter instance type: \n",
      "{\n",
      "    \"Groups\": [],\n",
      "    \"Instances\": [\n",
      "        {\n",
      "            \"AmiLaunchIndex\": 0,\n",
      "            \"ImageId\": \"ami-011c99152163a87ae\",\n",
      "            \"InstanceId\": \"i-0ac04145a3de1ee1c\",\n",
      "            \"InstanceType\": \"t2.micro\",\n",
      "            \"KeyName\": \"task6\",\n",
      "            \"LaunchTime\": \"2021-06-24T18:16:32+00:00\",\n",
      "            \"Monitoring\": {\n",
      "                \"State\": \"disabled\"\n",
      "            },\n",
      "            \"Placement\": {\n",
      "                \"AvailabilityZone\": \"ap-south-1a\",\n",
      "                \"GroupName\": \"\",\n",
      "                \"Tenancy\": \"default\"\n",
      "            },\n",
      "            \"PrivateDnsName\": \"ip-172-31-45-70.ap-south-1.compute.internal\",\n",
      "            \"PrivateIpAddress\": \"172.31.45.70\",\n",
      "            \"ProductCodes\": [],\n",
      "            \"PublicDnsName\": \"\",\n",
      "            \"State\": {\n",
      "                \"Code\": 0,\n",
      "                \"Name\": \"pending\"\n",
      "            },\n",
      "            \"StateTransitionReason\": \"\",\n",
      "            \"SubnetId\": \"subnet-7ed5c016\",\n",
      "            \"VpcId\": \"vpc-7111fd1a\",\n",
      "            \"Architecture\": \"x86_64\",\n",
      "            \"BlockDeviceMappings\": [],\n",
      "            \"ClientToken\": \"82d21936-0217-4301-9326-b7445c089dab\",\n",
      "            \"EbsOptimized\": false,\n",
      "            \"EnaSupport\": true,\n",
      "            \"Hypervisor\": \"xen\",\n",
      "            \"NetworkInterfaces\": [\n",
      "                {\n",
      "                    \"Attachment\": {\n",
      "                        \"AttachTime\": \"2021-06-24T18:16:32+00:00\",\n",
      "                        \"AttachmentId\": \"eni-attach-062e8913d4b97b32c\",\n",
      "                        \"DeleteOnTermination\": true,\n",
      "                        \"DeviceIndex\": 0,\n",
      "                        \"Status\": \"attaching\"\n",
      "                    },\n",
      "                    \"Description\": \"\",\n",
      "                    \"Groups\": [\n",
      "                        {\n",
      "                            \"GroupName\": \"task6\",\n",
      "                            \"GroupId\": \"sg-0455403df92009c8e\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"Ipv6Addresses\": [],\n",
      "                    \"MacAddress\": \"02:43:79:08:4b:8a\",\n",
      "                    \"NetworkInterfaceId\": \"eni-0bd2f14a76007c135\",\n",
      "                    \"OwnerId\": \"915987724195\",\n",
      "                    \"PrivateDnsName\": \"ip-172-31-45-70.ap-south-1.compute.internal\",\n",
      "                    \"PrivateIpAddress\": \"172.31.45.70\",\n",
      "                    \"PrivateIpAddresses\": [\n",
      "                        {\n",
      "                            \"Primary\": true,\n",
      "                            \"PrivateDnsName\": \"ip-172-31-45-70.ap-south-1.compute.internal\",\n",
      "                            \"PrivateIpAddress\": \"172.31.45.70\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"SourceDestCheck\": true,\n",
      "                    \"Status\": \"in-use\",\n",
      "                    \"SubnetId\": \"subnet-7ed5c016\",\n",
      "                    \"VpcId\": \"vpc-7111fd1a\",\n",
      "                    \"InterfaceType\": \"interface\"\n",
      "                }\n",
      "            ],\n",
      "            \"RootDeviceName\": \"/dev/xvda\",\n",
      "            \"RootDeviceType\": \"ebs\",\n",
      "            \"SecurityGroups\": [\n",
      "                {\n",
      "                    \"GroupName\": \"task6\",\n",
      "                    \"GroupId\": \"sg-0455403df92009c8e\"\n",
      "                }\n",
      "            ],\n",
      "            \"SourceDestCheck\": true,\n",
      "            \"StateReason\": {\n",
      "                \"Code\": \"pending\",\n",
      "                \"Message\": \"pending\"\n",
      "            },\n",
      "            \"VirtualizationType\": \"hvm\",\n",
      "            \"CpuOptions\": {\n",
      "                \"CoreCount\": 1,\n",
      "                \"ThreadsPerCore\": 1\n",
      "            },\n",
      "            \"CapacityReservationSpecification\": {\n",
      "                \"CapacityReservationPreference\": \"open\"\n",
      "            },\n",
      "            \"MetadataOptions\": {\n",
      "                \"State\": \"pending\",\n",
      "                \"HttpTokens\": \"optional\",\n",
      "                \"HttpPutResponseHopLimit\": 1,\n",
      "                \"HttpEndpoint\": \"enabled\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"OwnerId\": \"915987724195\",\n",
      "    \"ReservationId\": \"r-0ce025011f2d5b475\"\n",
      "}\n",
      "{\n",
      "    \"AvailabilityZone\": \"ap-south-1a\",\n",
      "    \"CreateTime\": \"2021-06-24T18:16:35+00:00\",\n",
      "    \"Encrypted\": false,\n",
      "    \"Size\": 1,\n",
      "    \"SnapshotId\": \"\",\n",
      "    \"State\": \"creating\",\n",
      "    \"VolumeId\": \"vol-0cdba8f35c984068c\",\n",
      "    \"Iops\": 100,\n",
      "    \"Tags\": [],\n",
      "    \"VolumeType\": \"gp2\",\n",
      "    \"MultiAttachEnabled\": false\n",
      "}\n",
      "Enter volume id: vol-07ef9584d501f88b1\n",
      "Enter instance id: \ti-0ac04145a3de1ee1c\n",
      "volume atteched \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = ronak_model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        #print(results)\n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        if confidence > 90:\n",
    "            \"\"\"if results[0]<100:\n",
    "                cv2.putText(image, \"Hey Ronak\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "                mail = send_email()\n",
    "                print(mail)\n",
    "                rt = whats()\n",
    "                print(rt)\"\"\"\n",
    "                    \n",
    "                    \n",
    "                \n",
    "            if results[0]>100:\n",
    "                cv2.putText(image, \"Hey other\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "                aw = aws()\n",
    "                print(aw)\n",
    "                break;\n",
    "            \n",
    "         \n",
    "        else:\n",
    "            \n",
    "            cv2.putText(image, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "def send_email():\n",
    "    mail_content = \"\"\"\n",
    "    This is Ronak trying to do task 6!!!\n",
    "    \"\"\"\n",
    "    #The mail addresses and password\n",
    "    sender_address = 'ronak.goyal.5001@gmail.com'\n",
    "    sender_pass = 'kingronki2001'\n",
    "    receiver_address = 'aniruddh.sharma0401@gmail.com'\n",
    "    #Setup the MIME\n",
    "    message = MIMEMultipart()\n",
    "    message['From'] = sender_address\n",
    "    message['To'] = receiver_address\n",
    "    message['Subject'] = 'Log-in detected.'   #The subject line\n",
    "    #The body and the attachments for the mail\n",
    "    message.attach(MIMEText(mail_content, 'plain'))\n",
    "    #Create SMTP session for sending the mail\n",
    "    session = smtplib.SMTP('smtp.gmail.com', 587) #use gmail with port\n",
    "    session.starttls() #enable security\n",
    "    session.login(sender_address, sender_pass) #login with mail_id and password\n",
    "    text = message.as_string()\n",
    "    session.sendmail(sender_address, receiver_address, text)\n",
    "    session.quit()\n",
    "    return('Mail Sent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whats app msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywhatkit as kit\n",
    "def whats():\n",
    "    kit.sendwhatmsg(\"+91 99507 18591\",\"Msg aa rha h!!\",23,45)\n",
    "    #kit.sendwhatmsg_instantly(\"+91 99507 18591\",\"Msg aa rha h!!\",20)\n",
    "    return \"msg sending\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#     aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess as sp\n",
    "def aws():\n",
    "    os.system(\"aws configure\")\n",
    "\n",
    "    #create key-value pair\n",
    "    sp.getoutput(\"aws ec2 create-key-pair --key-name task6\" )\n",
    "\n",
    "    #creating the security group\n",
    "    #sg=input(\"Enter your sg name: \")\n",
    "    #sp.getoutput(\"aws ec2 create-security-group --group-name {} --description \\\"My Security Group\\\" \".format(sg))\n",
    "\n",
    "    #authorizing the security group for ingress rules\n",
    "    #sg_id=input(\":Enter security group id: \")\n",
    "    #sp.getoutput(\"aws ec2 authorize-security-group-ingress --group-id {} --protocol all --cidr 0.0.0.0/0\".format(sg_id))\n",
    "\n",
    "    #launching the instance\n",
    "    image_id=input(\"Enter the image id: \")\n",
    "    inst_type=input(\"Enter instance type: \")\n",
    "    out = sp.getoutput(\"aws ec2 run-instances --image-id  ami-011c99152163a87ae --instance-type t2.micro --key-name task6 --security-group-ids sg-0455403df92009c8e --placement AvailabilityZone=\\\"ap-south-1a\\\" \")\n",
    "    #print(\"Instance Launched\")\n",
    "    print(out)\n",
    "    #creating the EBS volume\n",
    "    vol = sp.getoutput(\"aws ec2 create-volume --size 1 --availability-zone ap-south-1a\")\n",
    "    print(vol)\n",
    "    #Attaching the EBS to the instance launched\n",
    "    vol_id=input(\"Enter volume id: \")\n",
    "    inst_id=input(\"Enter instance id: \")\n",
    "    sp.getoutput(\"aws ec2 attach-volume --volume-id {} --instance-id {} --device /dev/sdx\".format(vol_id,inst_id))\n",
    "    return \"volume atteched \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\\nTo see help text, you can run:\\n\\n  aws help\\n  aws <command> help\\n  aws <command> <subcommand> help\\naws: error: argument subcommand: Invalid choice, valid choices are:\\n\\nlist                                     | get                                     \\nset                                      | add-model                               \\nimport                                   | list-profiles                           \\nsso                                      | wizard                                  '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
